{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraper_properati.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sQl7rC-UvDq-",
        "5ZLT6RzM7RpD"
      ],
      "authorship_tag": "ABX9TyOoqghsl9aOHy50F56T2Rl2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Murcicrum/Scrapers-de-inmobiliarias/blob/main/scraper_properati.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "havif6dou-AC"
      },
      "source": [
        "#####Importo módulos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK0rv64LeFHz"
      },
      "source": [
        "from numpy import random\n",
        "import pandas as pd\n",
        "import json\n",
        "import time\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as bs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nB-5TFWLuw4S"
      },
      "source": [
        "#####Defino la url de properati y los strings que defines mi busqueda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPN6lVTSfWTS"
      },
      "source": [
        "#URL de Properati con deptos en alquiler en caba, con menos de 5 años de antigüedad\n",
        "url_properati = 'https://www.properati.com.ar'\n",
        "\n",
        "#String que define las busquedas: deptos, casas y phs en caba, ordenadas por fecha de publicación\n",
        "#El número de pagina queda a completar, cada página muestra hasta 30 publicaciones\n",
        "string_search_deptos = '/s/capital-federal/departamento/alquiler?sort=published_on_desc&page='\n",
        "string_search_casas = '/s/capital-federal/casa/alquiler?sort=published_on_desc&page='\n",
        "string_search_phs = '/s/capital-federal/ph/alquiler?page='\n",
        "\n",
        "#por si pinta 403\n",
        "#headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0p_x280pJUo"
      },
      "source": [
        "#####Extraigo todos los links a las publicaciones que devuelve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QV2-njuS5Dh"
      },
      "source": [
        "def get_links(string_search:str, N_pags:int) -> list:\n",
        "  \n",
        "  url_properati='https://www.properati.com.ar'\n",
        "  url_deptos = []\n",
        "  \n",
        "  for i in range(1,N_pags+1):\n",
        "    url_search = url_properati + string_search + str(i)\n",
        "    response = requests.get( url_search )\n",
        "\n",
        "    if response.status_code==200:\n",
        "      print('Extrayendo links de página', i)\n",
        "      soup = bs(response.content)\n",
        "      tag_deptos = soup.findAll(name='div', attrs={'class':'StyledCardInfo-n9541a-2'})\n",
        "\n",
        "      for j,t in enumerate(tag_deptos):\n",
        "        url_depto = url_properati + t.find(name='a').attrs['href']\n",
        "        if url_depto not in url_deptos:\n",
        "          url_deptos.append( url_depto )\n",
        "    \n",
        "    else:\n",
        "      print(f'Fallo. Página: {i}, Status_code: {response.status_code}, URL: {url}')\n",
        "    \n",
        "    time.sleep(5*random.rand())  \n",
        "  print(f'Se extrajeron {len(url_deptos)} links')\n",
        "\n",
        "  return url_deptos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L8fBeeYzh95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de9c176e-45b4-4e46-8701-29128ad1cf4d"
      },
      "source": [
        "url_deptos = get_links( string_search_deptos, 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extrayendo links de página 1\n",
            "Extrayendo links de página 2\n",
            "Extrayendo links de página 3\n",
            "Extrayendo links de página 4\n",
            "Extrayendo links de página 5\n",
            "Extrayendo links de página 6\n",
            "Extrayendo links de página 7\n",
            "Extrayendo links de página 8\n",
            "Extrayendo links de página 9\n",
            "Extrayendo links de página 10\n",
            "Se extrajeron 232 links\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQl7rC-UvDq-"
      },
      "source": [
        "#####Para cada publicación extraer la data que nos interesa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTZQ7YrY3-_L"
      },
      "source": [
        "import csv\n",
        "\n",
        "def find_value(keys: str, dic: dict):\n",
        "  '''\n",
        "  Dado una secuencia de keys anidadas en el dict\n",
        "  Si encuentra cada una de las keys devuelve el valor, buscando recursivamente\n",
        "  '''\n",
        "  list_keys = keys.split('.')\n",
        "  if list_keys[0] in dic:\n",
        "\n",
        "    if len(list_keys)==1:\n",
        "      return dic[ list_keys[0] ]\n",
        "    else:\n",
        "      new_keys = '.'.join(list_keys[1:])\n",
        "      return find_value( new_keys, dic[list_keys[0]] )\n",
        "  \n",
        "  else:\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_data(urls: list,  to_extract: dict, filename: str='', n: int=30) -> list:\n",
        "  '''\n",
        "  Dada una lista con urls de publicaciones de properati\n",
        "  Arma una lista de diccionarios, donde cada uno tiene la misma estructura:\n",
        "    keys = las keys de to_extract\n",
        "    values = el valor que tenga el json de cada publicación en la secuencia de keys definida en los values de to_extract.\n",
        "  Si el json de una publicación no contiene una secuencia de keys expresada en un value de to_extract,\n",
        "  el valor que toma el diccionario es None.\n",
        "  Si se encuentras publicaciones finalizadas en urls o falló el request, se omiten.\n",
        "  ###REESCRBIR MEJOR\n",
        "  '''\n",
        "\n",
        "  data_list = []      \n",
        "    \n",
        "  for i, url in enumerate(urls):\n",
        "#Chequeo si el request sale bien y la publicación está disponible    \n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "      print(i, 'Falló en link \\t',  'Status_code: ', response.status_code,'\\t' ,url)\n",
        "      continue\n",
        "\n",
        "    soup = bs(response.content)\n",
        "\n",
        "    if 'Esta publicación ya no está disponible' == soup.find(name='h1', attrs={'class':'StyledTitle-mffpuc-0'}).text:\n",
        "      print(i, 'Finalizó la publicación ', url)\n",
        "      continue\n",
        "\n",
        "#Levanto los datos y los guardo en una lista\n",
        "    data_json = json.loads( soup.find(name='script', attrs={'id':'__NEXT_DATA__'}).string )\n",
        "    d_props = data_json['props']['pageProps']['property']\n",
        "\n",
        "    data = {}\n",
        "\n",
        "    for r, s in to_extract.items():\n",
        "      data[r] = find_value( s, d_props )\n",
        "    data['url']=url\n",
        "   \n",
        "    data_list.append(data)\n",
        "    \n",
        "#####Guardo los datos de a lotes si me diste un path\n",
        "    if filename and (i%n==0 or i==(len(urls)-1)):     \n",
        "      with open(filename, 'a') as f:  # You will need 'wb' mode in Python 2.x\n",
        "        w = csv.DictWriter(f, fieldnames=data.keys())\n",
        "        if i==0:  \n",
        "          print('Los datos se guardarán en', filename)\n",
        "          w.writeheader()\n",
        "          w.writerow( data_list[0] )\n",
        "        else:\n",
        "          print(i, 'Guardando...')\n",
        "          if i%n==0:\n",
        "            for data in data_list[-n:]:\n",
        "              w.writerow(data)\n",
        "          elif i==len(urls)-1:\n",
        "            for data in data_list[-(i%n):]:\n",
        "              w.writerow(data)\n",
        "\n",
        "    time.sleep(5*random.rand())  \n",
        "\n",
        "  return data_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZLT6RzM7RpD"
      },
      "source": [
        "#####Defino la data que quiero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNygmN19JH3m"
      },
      "source": [
        "#cada key es la key con la que quedará registrada cada valor que querramos extraer del json\n",
        "#cada value es un string con la secuencia de keys a recorrer en el json para extraer el valor deseado\n",
        "to_extract = {'ub_calle': 'address.street',                                     #\n",
        "              'ub_lat': 'geo_point.lat',                                        #\n",
        "              'ub_lon': 'geo_point.lon',                                        #\n",
        "              'pr_moneda': 'price.currency',                                    #\n",
        "              'pr_valor': 'price.amount',                                       #\n",
        "              'nu_ambs': 'floor_plan.rooms',                                    #\n",
        "              'nu_habs': 'floor_plan.bedrooms',                                 #\n",
        "              'sp_des': 'surface.total',                                        #\n",
        "              'sp_cub': 'surface.covered',                                      #\n",
        "              'fe_pub': 'published_on'}                                         #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfMI2f7ZZqDe"
      },
      "source": [
        "#####Descargo la data y la guardo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21oquC4q4Xxf",
        "outputId": "16b82e3a-ab6d-4523-c3a2-933e638e1dce"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "#os.listdir('drive/MyDrive/Colab Notebooks/Espacios públicos TDP/')\n",
        "#os.remove(save_filename)\n",
        "#os.listdir('drive/MyDrive/Colab Notebooks/Espacios públicos TDP/')\n",
        "path_drive = 'drive/MyDrive/Colab Notebooks/Espacios públicos TDP/'\n",
        "\n",
        "save_filename = path_drive + 'properati_deptos.csv'\n",
        "\n",
        "n_guardar = 10                #Cada cuantas entradas guardo en el csv\n",
        "data_deptos = get_data(url_deptos, to_extract, save_filename, n_guardar  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Los datos se guardarán en drive/MyDrive/Colab Notebooks/Espacios públicos TDP/properati.csv\n",
            "30 Guardando...\n",
            "60 Guardando...\n",
            "68 Finalizó la publicación  https://www.properati.com.ar/detalle/3ynrq_alquiler_departamento_colegiales_subte-linea-d_ciclovias-y-bicisendas-de-buenos-aires_cocina_encargado_vigilancia_gladys-fontela-soluciones-inmobiliarias_hmbr\n",
            "90 Guardando...\n",
            "120 Guardando...\n",
            "150 Guardando...\n",
            "180 Guardando...\n",
            "210 Guardando...\n",
            "231 Guardando...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roQ7dwIda7zV"
      },
      "source": [
        "Y ahora los puedo cargar en un dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TaVdIQJb_Ab",
        "outputId": "f03e0996-ece0-42b6-d853-97e904f05d9c"
      },
      "source": [
        "df = pd.read_csv(save_filename)\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 358 entries, 0 to 357\n",
            "Data columns (total 11 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   ub_calle   357 non-null    object\n",
            " 1   ub_lat     357 non-null    object\n",
            " 2   ub_lon     357 non-null    object\n",
            " 3   pr_moneda  358 non-null    object\n",
            " 4   pr_valor   358 non-null    object\n",
            " 5   nu_ambs    72 non-null     object\n",
            " 6   nu_habs    257 non-null    object\n",
            " 7   sp_des     331 non-null    object\n",
            " 8   sp_cub     50 non-null     object\n",
            " 9   fe_pub     358 non-null    object\n",
            " 10  url        358 non-null    object\n",
            "dtypes: object(11)\n",
            "memory usage: 30.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUn75_dnbALB"
      },
      "source": [
        "#Repito lo mismo para casas y phs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QORMXHrwZBho"
      },
      "source": [
        "url_casas = get_links( string_search_deptos, 10)\n",
        "save_filename = path_drive + 'properati_casas.csv'\n",
        "data_casas = get_data( url_casas, to_extract, save_filename, n_guardar )\n",
        "\n",
        "url_phs = get_links( string_search_phs, 10)\n",
        "save_filename = path_drive + 'properati_phs.csv'\n",
        "data_phs = get_data( url_phs, to_extract, save_filename, n_guardar )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}